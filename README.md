# Prompt Lab

A comprehensive repository for storing, organizing, and experimenting with various prompt templates for Large Language Models (LLMs). This homelab project aims to explore modern systems, automation, and AI-driven tooling through hands-on experimentation, focusing on practical applications and continuous learning.

## Vision

To understand cloud infrastructure, automation, and AI-driven tooling, emphasizing how systems work, connect, and evolve. This "Prompt Lab" serves as a dedicated space for crafting effective prompts across different domains, supporting the broader homelab vision.

## Structure

The repository is organized into several key directories, each serving a specific purpose related to prompt engineering and homelab management:

### `prompts/`
Contains categorized prompt templates for various software engineering and operations tasks.
- `coding/`: Prompts for code review, refactoring, explanation, and test generation.
- `architecture/`: Prompts for system design, tradeoff analysis, and scaling discussions.
- `devops/`: Prompts for infrastructure review, security analysis, and CI/CD pipeline design.
- `automation/`: Prompts for workflow design, comparing automation triggers (cron vs. event), and brainstorming automation ideas.
- `writing/`: Prompts for technical writing, documentation, and generating commit messages.
- `research/`: Prompts for comparing tools, learning new technologies, and summarizing content.
- `meta/`: Prompts for improving prompt quality, critiquing AI responses, and asking better questions.

### `templates/`
Contains reusable prompt frameworks and structures.
- `role-based.md`: Templates for defining AI roles to guide responses.
- `step-by-step.md`: Templates for generating multi-step instructions or guides.
- `critique-loop.md`: Templates for iterative feedback and refinement of AI outputs.
- `brainstorming.md`: Templates for creative idea generation.

### `experiments/`
Dedicated to exploring advanced prompting techniques and model behaviors.
- `model-variants.md`: Prompts for comparing outputs from different LLM models.
- `long-context.md`: Prompts designed to test the capabilities of models with extended context windows.
- `prompt-ideas.md`: A sandbox for novel and experimental prompt concepts.

### `archive/`
Stores deprecated or outdated prompt templates.
- `deprecated-prompts.md`: Examples of prompts that are no longer actively used or maintained.

## Getting Started

To explore the prompts, simply navigate through the directories. Each `.md` file contains a sample prompt that you can adapt and use.

## Contribution

Contributions are welcome! If you have a useful prompt template or an idea for a new category, feel free to contribute.